# 벡터가 뭐에요?
- 벡터의 기본 개념과 연산, 노름에 대해 소개
- 두 벡터 사이의 거리와 각도, 그리고 내적에 대해 설명
- **벡터**는, 딥러닝에서 매우 중요한 **선형대수학**의 기본 단위가 되고, numpy에서도 굉장히 많이 사용되는 연산!
> 공간에서 어떤 의미를 가지는지 이해!\
> 노름이나 내적의 개념도 실제 머신러닝에서 어떻게 사용되는지!

---

## 학습 날짜
> 2022-06-20

## 학습 시간
> PM 5:38 ~ 5:55
> PM 11:12 ~ 11:40

---

### 벡터?
- 숫자를 원소로 가지는 **리스트** 또는 **배열**
```python
import numpy as np
x = [1, 7, 2]
x = np.array([1, 7, 2])
```
- 벡터의 차원 : 원소의 개수.
- 벡터는 공간에서의 **한 점**
- 벡터는 원점으로부터 상대적 **위치**를 표현
- 일반적으로 화살표로 표현
- 벡터에 숫자를 곱하면 길이만 변한다. : 스칼라곱 (방향은 그대로)
```
a > 1 길이 증가
a < 1 길이 감소
a < 0 반대 방향
```
- 벡터끼리 **같은 모양**을 가지면 덧셈, 뺄셈이 가능 (차원이 같은 벡터끼리 덧셈, 뺄셈)
- 벡터끼리 **같은 모양**을 가지면 성분곱(Hadamard product)을 계산할 수 있다. (원소끼리의 곱::Xd*Yd)

### 벡터의 덧셈
- 원점 :: 0벡터
- 벡터 X :: 0 + X 벡터 -> 원점으로부터 상대적 위치!
- 두 벡터의 덧셈은 다른 벡터로부터 **상대적 위치이동**!
```
Y [2, 2]
벡터 X 는 [0, 0] --> [0, 0] + X[1, 0]
벡터 Y + X 는 Y[2, 2] +  X[1, 0] :: Y[2, 2] --> Y+X[3, 2]
```

### 벡터의 뺄셈
-  Y - X 는 Y + (-X) 로 생각한다.
-  벡터의 뺄셈은 방향을 반대로 뒤집은 덧셈

### 벡터의 노름 (norm)
- norm : **원점에서부터의 거리**
- ||X||1 : L1 norm ```||X||1 = sigma |Xi|```
- ||X||2 : L2 norm ```||X||2 = root(sigma |Xi|**2)``` : 
- **벡터의 norm 은 임의의 차원 d 에 대해 성립한다.**
- 벡터의 차원(구성성분의 개수)에 상관없이 계산 가능

### norm 계산
-  L1 norm : 각 성분의 **변화량의 절대값**을 모두 더한다.
-  - 좌표축을 따라 이동한 거리이다.
-  - ex) |X1| + |X2|
-  L2 norm : 피타고라스 정리를 이용해 **유클리드 거리**이다.
-  - 두 점 사이의 거리
```python
# x는벡터
def l1_norm(x):
  x_norm = np.abs(x)
  x_norm = np.sum(x_norm)
  return x_norm

# L2-norm은 np.linalg.norm 을 이용해도 구현 가능.
def l2_norm(x):
  x_norm = x*x
  x_norm = np.sum(x_norm)
  x_norm = np.sqrt(x_norm)
  return x_norm
```

---
### norm의 종류에 따라 기하하적 성질이 달라진다.
- L1-norm의 원은 원점을 기준으로 마름모 모양: {X: ||X||1 = 1}
- - L1 norm은 좌표죽을 기준으로 움직인 거리이기 때문에 마름모 모양으로 나타남
- L2-norm의 원은 일반적으로 알고있는 원점을부터 1만큼 떨어진 원 모양 {X: ||X||2 = 1}
- - L2 norm은 유클리드 거리이기 때문에 직선 거리에 따라 나타나므로 원 모양으로 나타남
- 머신러닝에서는 각 성질들이 필요할 때가 있으므로 둘 다 사용한다.
- - L1 : Robust 학습, Lasso 회귀
- - L2 : Laplace 근사, Ridge 회귀

### L1, L2 norm을 사용해 두 벡터 사이의 거리를 계산
- 두 점 사이의 거리를 계산한다.
- 두 벡터 사이의 거리를 계산할 떄는 **벡터의 뺄셈**을 이용한다.
- ||Y - X|| == ||X - Y||

### 두 벡터 사이의 거리를 이용해 각도 계산이 가능
- 단, L2 norm 에서만 가능하다
- **제2 코사인 법칙**에 의해 두 벡터 사이의 각도를 계산할 수 있다.
- ||X||2**2 + ||Y||2**2 - ||X - Y||2**2 ==> 벡터의 내적 2<X, Y>
- 내적 : 두 벡터의 각 성분들의 곱들의 합 sigma(Xi * Yi)
```python
#벡터의 내적 np.inner(a, b)
def angle(x, y):
  v = np.inner(x, y) / (l2_norm(x) * l2_norm(y))
  # v :: cos(@)
  theta = np.arccos(v)
  return theta
```

### 내적
- 내적은 **정사영된 벡터의 길이**와 관련이 있다.
- 내적은 정사영의 길이를 **벡터 Y의 길이 ||Y||1 만큼 조정**한 값이다.
- 두 벡터의 유사도를 측정하는데 사용 가능
- 머신러닝에서는 두 데이터가 얼만큼 유사한가, 두 패턴이 얼만큼 유사한가
- 두 벡터가 비슷한 방향으로 진행하는지 확인 가능.
