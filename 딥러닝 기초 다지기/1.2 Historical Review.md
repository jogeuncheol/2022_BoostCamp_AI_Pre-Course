# 딥러닝의 역사
- 2012년부터 2020년까지의 패러다임에 대해
- 트랜드의 변화

---

## 학습 날짜
> 2022-06-20
## 학습 시간
> PM 4:47 ~ 5:15

---

- 딥러닝이라는것은 다른 머신러닝 방법

### 2012년 AlexNet
- Convolution Network
- 224x224 이미지 분류 문제
- 딥러닝을 이용해 처음으로 ILSVRD 이미지넷 대회에서 1등
- 이전에는 커널기반, SVM 등 고전적인 머신러닝 기법 사용되어왔는데 AlexNet 이후 딥러닝을 사용하지 않은 방법은 1등을 하지 못함.
- 역사적으로 딥러닝의 패러다임 시작

### 2013년 DQN
- 알파고!
- 강화학습

### 2014년 Encoder / Decoder
- NMT
- 문장, 단어를 이해하고 다른 언어로 변환
- 기계어 번역의 흐름

### Adam
- Optimizer
- SGD, RMSProp ... 
- Adam이 결과가 좋기 때문에 일반적으로 많이 쓴다.
- 왜 Optimizer를 SGD, Adam 을 사용했는지 설명이 없지만, 최적의 성능이 나오기 때문에

### 2015년 GAN
- Generative Adversarial Network
- 적대적 생성 네트워크
- 생성자와 판별자

### ResNet
- 딥러닝의 딥러닝이 가능해졌다.
- 딥러닝 :: 네트워크를 깊게 쌓았다.
- 이전까지는 네트워크를 깊게 할 수록 성능이 좋지 않았다.
- ResNet 이후 10 layer 이상에서 성능이 나빠지던 것을 100 layer까지 쌓아도 테스트 데이터에서 좋은 성능을 보여줌

### 2017년 Transformer
- Attention Is All You Need 구글 논문!
- 이 구조를 이해하는 것은 중요하다!
- 왜 이 구조가 좋은 성능을 내는지

### 2018년 Bert
- Bidirectional Encoder Representations from Transformers
- (find-tuned NLP models)
- 자연어 처리

### 2019년 BIG Language Models (GPT-X)
- Bert의 끝판왕 GPT-3
- 자연어 처리 모델
- 175 billion parameters!

### 2020년 Self-Supervised Learning
- SimCLR: a Simple framework for Contrastive Learning of visual Representations
- 이미지 분류 문제를 풀고 싶은데 한정된 학습 데이터를 주었을 때, Label을 모르는 데이터를 학습에 같이 사용
- 지도학습과 비지도학습을 같이 사용해 실제 풀고자하는 분류 문제에 좋은 성능!
- 활발히 연구 진행중
